{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "\n",
    "[Example from MLNotebook - A simple Nerual Network with numpy in python](https://mlnotebook.github.io/post/nn-in-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\t [0.47535038] \t[0.]\n",
      "[1 1]\t [0.54267316] \t[0.]\n",
      "[0 1]\t [0.50460014] \t[1.]\n",
      "[1 0]\t [0.51350405] \t[1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "    \n",
    "class BackPropagationNetwork:\n",
    "    num_layers = 0\n",
    "    shape = None\n",
    "    weights = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x, Derivative=False):\n",
    "        \"\"\"\n",
    "        sigmoid maps the input to a value between 0 and 1 but not equal to 0 or 1.\n",
    "        It means output will be high signal if positive and low signal if negative.\n",
    "        Simoid's natural threshold is o.5, so any input above will be hig or 1 in binary.\n",
    "        \"\"\"\n",
    "        if not Derivative:\n",
    "            return 1 / (1 + np.exp (-x))\n",
    "        else:\n",
    "            out = BackPropagationNetwork.sigmoid(x)\n",
    "            return out * (1 - out)\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_nodes):\n",
    "        self.num_layers = len(num_nodes) - 1\n",
    "        self.shape = num_nodes\n",
    "        self._layer_input = []\n",
    "        self._layer_output = []\n",
    "        \n",
    "        for (l1, l2) in zip(num_nodes[:-1], num_nodes[1:]):\n",
    "            self.weights.append(np.random.normal(scale=0.1, size=(l2, l1 + 1)))\n",
    "        \n",
    "    \n",
    "    def fp(self, i_data):\n",
    "        \"\"\"\n",
    "        Forward pass get input and run it through the NN\n",
    "        \n",
    "        O⃗j = σ(Wij O⃗I)\n",
    "        \n",
    "        σ is the activation transfer function or sigmoid in this case,\n",
    "        which is applied element wise to the product of the matrices.\n",
    "        \n",
    "        I is our input layer\n",
    "        J is our hidden layer\n",
    "        Wij is the weight connecting the ith node in I to the jth node in J\n",
    "    \n",
    "        \"\"\"\n",
    "        delta = []\n",
    "        num_examples = i_data.shape[0]\n",
    "        # clean values from prevous layer\n",
    "        self._layer_input = []\n",
    "        self._layer_output = []\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                layer_input = self.weights[0].dot(np.vstack([i_data.T, np.ones([1, num_examples])]))\n",
    "            else:\n",
    "                layer_input = self.weights[i].dot(np.vstack([i_data.T, np.ones([1, num_examples])]))\n",
    "            \n",
    "            self._layer_input.append(layer_input)\n",
    "            self._layer_output.append(self.sigmoid(layer_input))\n",
    "                \n",
    "        return self._layer_output[-1].T\n",
    "        \n",
    "        \n",
    "    def bp(self, i_data, target, t_rate = 0.2):\n",
    "        \"\"\"Train epoch (back propagation) get the erro, deltas and back propagate to update the weights\"\"\"\n",
    "        delta = []\n",
    "        num_examples = i_data.shape[0]\n",
    "        self.fp(i_data)\n",
    "        \n",
    "        # Calculate the deltas\n",
    "        # δ⃗ K=σ′(WJKO⃗ J)∗(O⃗ K−TK)\n",
    "        # This is back propagation, we use the reversed function to ensure\n",
    "        # the algorithm considers the ayers in reverse order.\n",
    "        for i in reversed(range(self.num_layers)):\n",
    "            if i == self.num_layers - 1:\n",
    "                # If the output layer, then compare to the target values\n",
    "                o_delta = self._layer_output[i] - target.T\n",
    "                error = np.sum(o_delta**2)\n",
    "                delta.append(o_delta * self.sigmoid(self._layer_input[i], True))\n",
    "            else:\n",
    "                delta_pullback = self.weights[i + 1].T.dot(delta[-1])\n",
    "                delta.append(delta_pullback[:-1,:] * self.sigmoid(self._layer_input[i], True))\n",
    "\n",
    "        # Compute updates to each weight\n",
    "        for i in range(self.num_layers):\n",
    "            delta_index = self.num_layers - 1 - i    \n",
    "            if i == 0:\n",
    "               layer_output = np.vstack([i_data.T, np.ones([1, num_examples])])\n",
    "            else:\n",
    "                # If a hidden layer. compare to the following layer's delta\n",
    "                layer_output = np.vstack([self._layer_output[i - 1], np.ones([1, self._layer_output[i - 1].shape[1]])])\n",
    "            \n",
    "            # Update wights\n",
    "            # δ⃗ J = σ′(WIJOI)∗W⊺JKδ⃗ K\n",
    "            this_weight_deta = np.sum(layer_output[None,:,:].transpose(2, 0, 1) * delta[delta_index][None,:,:].transpose(2, 1, 0), axis = 0)\n",
    "            weight_delta = t_rate * this_weight_deta\n",
    "            \n",
    "            self.weights[i] -= weight_delta\n",
    "            \n",
    "        return error\n",
    "\n",
    "inp = np.array([[0,0],[1,1],[0,1],[1,0]])\n",
    "tar = np.array([[0.0],[0.0],[1.0],[1.0]])\n",
    "\n",
    "bpn = BackPropagationNetwork((2,2,1))\n",
    "\n",
    "Error = bpn.bp(inp, tar)\n",
    "Output = bpn.fp(inp)\n",
    "for i in range(inp.shape[0]):\n",
    "    print('{0}\\t {1} \\t{2}'.format(inp[i], Output[i], tar[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration\n",
    "\n",
    "We just tell our algorithm to repeat a maximum of `max_iterations` times or until the `error` is below `min_error` (whichever comes first). As the weights are stored internally within NN every time we call the `bp` method, it uses the latest, internally stored weights and doesn’t start again - the weights are only initialised once upon creation of NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\tError: 1.002551\n",
      "Iteration 2500\tError: 1.006508\n",
      "Iteration 5000\tError: 1.043235\n",
      "Iteration 7500\tError: 1.006910\n",
      "Iteration 10000\tError: 1.003430\n",
      "Iteration 12500\tError: 1.002238\n",
      "Iteration 15000\tError: 1.001647\n",
      "Iteration 17500\tError: 1.001298\n",
      "Iteration 20000\tError: 1.001069\n",
      "Iteration 22500\tError: 1.000907\n",
      "Iteration 25000\tError: 1.000786\n",
      "Iteration 27500\tError: 1.000694\n",
      "Iteration 30000\tError: 1.000620\n",
      "Iteration 32500\tError: 1.000561\n",
      "Iteration 35000\tError: 1.000511\n",
      "Iteration 37500\tError: 1.000470\n",
      "Iteration 40000\tError: 1.000434\n",
      "Iteration 42500\tError: 1.000404\n",
      "Iteration 45000\tError: 1.000377\n",
      "Iteration 47500\tError: 1.000354\n",
      "Iteration 50000\tError: 1.000333\n",
      "Iteration 52500\tError: 1.000315\n",
      "Iteration 55000\tError: 1.000298\n",
      "Iteration 57500\tError: 1.000283\n",
      "Iteration 60000\tError: 1.000270\n",
      "Iteration 62500\tError: 1.000257\n",
      "Iteration 65000\tError: 1.000246\n",
      "Iteration 67500\tError: 1.000236\n",
      "Iteration 70000\tError: 1.000226\n",
      "Iteration 72500\tError: 1.000218\n",
      "Iteration 75000\tError: 1.000210\n",
      "Iteration 77500\tError: 1.000202\n",
      "Iteration 80000\tError: 1.000195\n",
      "Iteration 82500\tError: 1.000188\n",
      "Iteration 85000\tError: 1.000182\n",
      "Iteration 87500\tError: 1.000176\n",
      "Iteration 90000\tError: 1.000171\n",
      "Iteration 92500\tError: 1.000166\n",
      "Iteration 95000\tError: 1.000161\n",
      "Iteration 97500\tError: 1.000157\n",
      "Iteration 100000\tError: 1.000152\n",
      "[0 0]\t [0.00949557] \t[0.]\n",
      "[1 1]\t [0.99999997] \t[0.]\n",
      "[0 1]\t [0.9995412] \t[1.]\n",
      "[1 0]\t [0.99212493] \t[1.]\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 100000\n",
    "min_error = 1e-5\n",
    "error = None\n",
    "bpn = BackPropagationNetwork((2,2,1))\n",
    "for i in range(max_iterations + 1):\n",
    "    error = bpn.bp(inp, tar)\n",
    "    if i % 2500 == 0:\n",
    "        print(\"Iteration {0}\\tError: {1:0.6f}\".format(i, error))\n",
    "    if error <= min_error:\n",
    "        print(\"Minimum error reached at iteration {0}\".format(i))\n",
    "        break\n",
    "\n",
    "Output = bpn.fp(inp)\n",
    "for i in range(inp.shape[0]):\n",
    "    print('{0}\\t {1} \\t{2}'.format(inp[i], Output[i], tar[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_propagation.fp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
